import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger
from src.pl_data_modules import DataModule
from src.pl_model_modules import MetaphorModel
from src.pl_callbacks import ClassificationMetricsCallback
import conf
import torch
import pandas as pd
from sklearn.metrics import f1_score
import os
import sys
torch.cuda.empty_cache()  # æ¸…ç†ç¼“å­˜

print(">>> å½“å‰ Python æ‰§è¡Œæ–‡ä»¶ï¼š", os.path.abspath(__file__))
print(">>> å½“å‰å·¥ä½œç›®å½•ï¼š", os.getcwd())
print(">>> Python æ¨¡å—è·¯å¾„ï¼š", sys.path)

import src.wsd.dataset
print(">>> åŠ è½½çš„ dataset.py è·¯å¾„ï¼š", src.wsd.dataset.__file__)

def main():
    # Seed for reproducibility
    pl.seed_everything(conf.seed)

    # Initialize TensorBoard Logger
    logger = TensorBoardLogger("logs/", name="metaphor_classification")

    # Initialize data module
    datamodule = DataModule(
        train_path=conf.train_path,
        val_path=conf.val_path,
        test_path=conf.test_path,
        batch_size=conf.batch_size,
    )

    # Initialize model
    model = MetaphorModel(
        model_name=conf.pmodel["name"],
        num_classes=4,
        lr=conf.lr,
    )

    # Callbacks
    callbacks = [
        ClassificationMetricsCallback(),
        ModelCheckpoint(
            monitor="val_loss",  # ç›‘æ§éªŒè¯é›†æŸå¤±
            mode="min",  # é€‰æ‹©æœ€å°çš„ val_loss ä½œä¸ºæœ€ä¼˜æ¨¡å‹
            save_top_k=1,  # åªä¿å­˜æœ€ä½³æ¨¡å‹
            dirpath="checkpoints",
            filename="best_model",
            save_weights_only=True,  # **ä»…ä¿å­˜æ¨¡å‹æƒé‡ï¼Œé˜²æ­¢åŠ è½½é—®é¢˜**
        ),
    ]

    # Trainer configuration
    trainer = pl.Trainer(
        max_epochs=conf.max_epochs,
        gpus=conf.gpus,
        precision=conf.precision,
        callbacks=callbacks,
        deterministic=conf.deterministic,
        logger=logger,  # **è®°å½•æ—¥å¿—**
        log_every_n_steps=10,  # **æ¯ 10 æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—**
        accumulate_grad_batches=2,  # æ¯ 2 ä¸ªå° batch æ‰è¿›è¡Œä¸€æ¬¡æ›´æ–°
    )

    # Train the model
    trainer.fit(model, datamodule=datamodule)

    test_results = []
    for dataset_name, test_path in conf.test_datasets.items():
        print(f"\nğŸ” Testing on dataset: {dataset_name}")

        test_datamodule = DataModule(
            train_path=conf.train_path,
            val_path=conf.val_path,
            test_path=test_path,
            batch_size=conf.batch_size,
        )
        test_datamodule.setup(stage="test")
        test_datamodule.set_dataset_name(model)

        # è¿è¡Œæµ‹è¯•
        results = trainer.test(model, datamodule=test_datamodule)[0]


        # è®°å½• F1-score
        #results["F1-score"] = f1
        #results["dataset"] = dataset_name
        #test_results.append(results)


        # è®°å½•æµ‹è¯•ç»“æœ
        results["dataset"] = dataset_name
        test_results.append(results)

        # è®°å½•åˆ° TensorBoard
        for metric, value in results.items():
            if metric != "dataset":
                logger.experiment.add_scalar(f"test/{dataset_name}/{metric}", value, global_step=trainer.global_step)


if __name__ == "__main__":
    main()